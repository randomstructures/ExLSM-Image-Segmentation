{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a 3D Unet Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Notebook initialized with ipy backend.\n"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os, time\n",
    "from importlib import reload\n",
    "\n",
    "# 3D visualization tools\n",
    "from mayavi import mlab\n",
    "mlab.init_notebook(backend='ipy')\n",
    "\n",
    "import tensorflow as tf\n",
    "import model, utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules providing tools for image manipulation\n",
    "import sys\n",
    "sys.path.append('../tools/')\n",
    "import mosaic, deformation, affine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<module 'affine' from '../tools\\\\affine.py'>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Reload of custom libraries to test hot-fixes\n",
    "reload(utilities)\n",
    "reload(model)\n",
    "reload(deformation)\n",
    "reload(affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1 Physical GPUs, 1 Logical GPUs\n"
    }
   ],
   "source": [
    "# Fix for tensorflow-gpu issues that I found online... (don't ask me what it does)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Network Arithmetics\n",
    "\n",
    "### Graphics memory\n",
    "While the architecture of the Unet is agnostic regarding the shape of it's 3D Input efficient evaluation demands constant input size.\n",
    "The first call of the Unet model triggers the allocation of GPU memory. Beside the massive number of parameters, the 3D tensors itself have large memory requirements. The maximum input tensor size is therefore directly determined by the available graphics memory of the GPU.\n",
    "\n",
    "The size of 220px^3 input cubes with 8 initial filters has been determined to lie close to the memory max of my personal computer (6 GB graphics memory)\n",
    "On the Janelia desktop computer (12GB graphics memory) up to 300px^3 cubes can be used.\n",
    "\n",
    "The voxel size of the single fru labeled neuron dataset is specified as roghly (0.1 um x 0.1 um x 0.18 um).\n",
    "### Reduction of output size\n",
    "Since the Unet architecture relies only on valid convolution operations, the size of the output tensor is reduced with respect to the input. The unet architecture requires an even tensor shape before every max pooling operation. This narrows down the permissible input sizes. utilities.check_size() performs the necessary calculations to check which input sizes are valid and what output dimensions result from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[92, 100, 108, 116, 124, 132, 140, 148, 156, 164, 172, 180, 188, 196, 204, 212, 220, 228, 236, 244, 252, 260, 268, 276, 284, 292, 300, 308, 316, 324, 332, 340, 348, 356, 364, 372, 380, 388, 396, 404, 412, 420, 428, 436, 444, 452, 460, 468, 476, 484, 492, 500, 508]\nOutput shape at 220 is 132.0 (mask_crop = 44.0)\n"
    }
   ],
   "source": [
    "# Get permissible network input sized (cube lengths)\n",
    "n_blocks = 2 # The number of downsample und upsample blocks in each branch of the network.\n",
    "valid_inputs = [n for n in range(512) if utilities.check_size(n, n_blocks=n_blocks)[0]]\n",
    "print(valid_inputs)\n",
    "# Check ouput for a given input size\n",
    "cube_length = 220\n",
    "output_length = utilities.check_size(cube_length, n_blocks)[1]\n",
    "print('Output shape at {} is {} (mask_crop = {})'.format(cube_length,output_length,\n",
    "                                                        (cube_length-output_length)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model (build is triggered on first call)\n",
    "unet = model.Unet(n_blocks=2, initial_filters=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"Unet\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_block (InputBlock)     multiple                  3696      \n_________________________________________________________________\ndownsample_block (Downsample multiple                  20784     \n_________________________________________________________________\ndownsample_block_1 (Downsamp multiple                  83040     \n_________________________________________________________________\nbottleneck_block (Bottleneck multiple                  463168    \n_________________________________________________________________\nupsample_block (UpsampleBloc multiple                  475328    \n_________________________________________________________________\nupsample_block_1 (UpsampleBl multiple                  118880    \n_________________________________________________________________\noutput_block (OutputBlock)   multiple                  27714     \n=================================================================\nTotal params: 1,192,610\nTrainable params: 1,192,610\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Input Pipeline\n",
    "\n",
    "The whole dataset has a size in the order of terabytes. At this stage we only work with preextracted volumes of (220px)^3 size.\n",
    "Heavy use of data augumentation should enable the network to learn efficiently from a very low number of annotated samples.\n",
    "\n",
    "the utilities module offers a custom keras.util.Sequence object that performs real time data augumentation. At the moment these operations consume a lot of time and could take up a lot of additional time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some slices from the dataset\n",
    "\n",
    "# Locate the sample directory on the computer\n",
    "base_dir = 'C:\\\\Users\\\\Linus Meienberg\\\\Documents\\\\ML Datasets\\\\FruSingleNeuron_20190707\\\\SampleCrops'\n",
    "samples = os.listdir(base_dir)\n",
    "\n",
    "# Load all sample training data\n",
    "samples = [utilities.load_volume(os.path.join(base_dir, sample)) for sample in samples] # List of dicts\n",
    "train_images = [sample['image'] for sample in samples] # List of image tensors\n",
    "train_masks = [sample['mask'] for sample in samples] # List of mask tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Sequence holds 1 batches\n"
    }
   ],
   "source": [
    "#TODO explore techniques to speed up image augumentation and batch preparation\n",
    "train_sequence = utilities.Dataset3D(batch_size=4, batches = 1, images=train_images, masks=train_masks, mask_crop=44, augument=True, elastic=False, affine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization and augumentation tools\n",
    "\n",
    "The following section is a quick demonstration of the 3D visualization and image augumentation tools provided by the utilities, affine and deformation module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xf4\\x00\\x00\\x01\\xf4\\x08\\x02\\x00\\x00\\x00D\\xb4H\\xd…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a912c152960a40c382fc5d7e30392061"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "#Load the first sample as a test case\n",
    "sample = utilities.load_volume(os.path.join(base_dir, samples[0])) # Dicttionary holding image and mask tensor\n",
    "utilities.show3DImage(sample['image']) # Visualize image data using some isosurfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xf4\\x00\\x00\\x01\\xf4\\x08\\x02\\x00\\x00\\x00D\\xb4H\\xd…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9811e4a8151c4fc1a46c0f678d82ca42"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "utilities.show3DImage(sample['mask'], mode='mask') # Visualize mask data with slightly different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(array([28756806,  3184260,     2934], dtype=int64),\n array([0., 1., 2., 3.], dtype=float32))"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "np.histogram(sample['mask'], bins=3)\n",
    "#BUG The mask seems to contain integer values up to 3 how does that come? what does it signify? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrate the use of the elastic deformation tool implemented in the deformation module\n",
    "displacement = deformation.displacementGridField3D((220,220,220), n_lines=5) # define a 3D vector field that is applied to the image coordinates\n",
    "sample_img_deformed = deformation.applyDisplacementField3D(sample['image'], *displacement)\n",
    "sample_mask_deformed = deformation.applyDisplacementField3D(sample['mask'], *displacement, interpolation_order= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xf4\\x00\\x00\\x01\\xf4\\x08\\x02\\x00\\x00\\x00D\\xb4H\\xd…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2997c93efd94458cb4274453756d4ac6"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "utilities.show3DImage(sample_img_deformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x01\\xf4\\x00\\x00\\x01\\xf4\\x08\\x02\\x00\\x00\\x00D\\xb4H\\xd…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87d6bb16e7784d83bec1e0725025140c"
      }
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Directly visualize a tensor in the batch structure generated by utilities.Dataset3D\n",
    "test_batch = train_sequence.__getitem__(0) test_batch = train_sequence.__getitem__(0) \n",
    "utilities.show3DImage(test_batch[0][0,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "TensorShape([1, 132, 132, 132, 2])"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37764bitmlgpuconda09ab47ec0af1474a87a3758d948ae547",
   "display_name": "Python 3.7.7 64-bit ('MLGPU': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}