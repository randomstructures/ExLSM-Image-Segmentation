{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic deformation of 2D images\n",
    "\n",
    "[Code by gangadhar provided on Kaggle](https://www.kaggle.com/gangadhar/nuclei-segmentation-in-microscope-cell-images)\n",
    "\n",
    "This notebook presents an image augmentation method that uses both local distortion and random affine transformation.\n",
    "\n",
    "These transformations uses anti-aliasing for high-quality output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from scipy.ndimage.interpolation import map_coordinates\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to distort image\n",
    "def elastic_transform(image, alpha, sigma, alpha_affine, random_state=None):\n",
    "    \"\"\"Elastic deformation of images as described in [Simard2003]_ (with modifications).\n",
    "    .. [Simard2003] Simard, Steinkraus and Platt, \"Best Practices for\n",
    "         Convolutional Neural Networks applied to Visual Document Analysis\", in\n",
    "         Proc. of the International Conference on Document Analysis and\n",
    "         Recognition, 2003.\n",
    "\n",
    "     Based on https://gist.github.com/erniejunior/601cdf56d2b424757de5\n",
    "    \"\"\"\n",
    "    if random_state is None:\n",
    "        random_state = np.random.RandomState(None)\n",
    "\n",
    "    shape = image.shape\n",
    "    shape_size = shape[:2]\n",
    "    \n",
    "    # Random affine\n",
    "    center_square = np.float32(shape_size) // 2\n",
    "    square_size = min(shape_size) // 3\n",
    "    pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
    "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
    "    dz = np.zeros_like(dx)\n",
    "\n",
    "    x, y, z = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]), np.arange(shape[2]))\n",
    "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1)), np.reshape(z, (-1, 1))\n",
    "\n",
    "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define function to draw a grid\n",
    "def draw_grid(im, grid_size):\n",
    "    # Draw grid lines\n",
    "    for i in range(0, im.shape[1], grid_size):\n",
    "        cv2.line(im, (i, 0), (i, im.shape[0]), color=(255,))\n",
    "    for j in range(0, im.shape[0], grid_size):\n",
    "        cv2.line(im, (0, j), (im.shape[1], j), color=(255,))\n",
    "\n",
    "# Load images\n",
    "im = cv2.imread(\"../input/train/10_1.tif\", -1)\n",
    "im_mask = cv2.imread(\"../input/train/10_1_mask.tif\", -1)\n",
    "\n",
    "# Draw grid lines\n",
    "draw_grid(im, 50)\n",
    "draw_grid(im_mask, 50)\n",
    "\n",
    "# Merge images into separete channels (shape will be (cols, rols, 2))\n",
    "im_merge = np.concatenate((im[...,None], im_mask[...,None]), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First sample...\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Apply transformation on image\n",
    "im_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 2, im_merge.shape[1] * 0.08, im_merge.shape[1] * 0.08)\n",
    "\n",
    "# Split image and mask\n",
    "im_t = im_merge_t[...,0]\n",
    "im_mask_t = im_merge_t[...,1]\n",
    "\n",
    "# Display result\n",
    "plt.figure(figsize = (16,14))\n",
    "plt.imshow(np.c_[np.r_[im, im_mask], np.r_[im_t, im_mask_t]], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Second sample (heavyer transform)...\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Apply transformation on image\n",
    "im_merge_t = elastic_transform(im_merge, im_merge.shape[1] * 3, im_merge.shape[1] * 0.07, im_merge.shape[1] * 0.09)\n",
    "\n",
    "# Split image and mask\n",
    "im_t = im_merge_t[...,0]\n",
    "im_mask_t = im_merge_t[...,1]\n",
    "\n",
    "# Display result\n",
    "plt.figure(figsize = (16,14))\n",
    "plt.imshow(np.c_[np.r_[im, im_mask], np.r_[im_t, im_mask_t]], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}