"""  
A collection of tools to tile images for the use with a fully convolutional network.
Linus Meienberg
June 2020
"""

#%% Imports 
import PIL
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf 

import concurrent.futures
from tqdm import tqdm

#%% Define a tool for visual control of tiling patterns

def showTiling(image, bounding_boxes):
    """Draw an image and visualize a collection of bounding boxes

    Parameters
    ----------
    image : image tensor
        The image to show as a background for the tiling layout
    bounding_boxes : list
        a list of bounding boxes specified as 4-tuples (x,y,w,h) in image coordinates where x,y denote the coordinates of the top left corner and w,h the width and height of the bounding box
    """
    plt.figure(figsize=(10,10))
    plt.imshow(image, origin='upper')
    rectangles = []
    for box in bounding_boxes:
        box = image_to_plot(box) # transform to plot coordinates
        rect = plt.Rectangle(box[0:2], box[2], box[3], fill=False)
        plt.gca().add_patch(rect)
    
    plt.show()

#%%
def rectangularTiling(image_shape, rectangle):
    """
    Completely covers a target image with a rectangular tile in two or three dimensions

    Parameters
    ----------
    image_shape : tuple
        the dimensions of the image that should be tiled
    rectangle : tuple
        the dimensions of the rectangular tile 

    Returns
    -------
    list
        list of bounding boxes specified as axis aligned bounding boxes (x,y,w,h) or (x,y,z,w,h,d)
    """
    assert len(image_shape) == len(rectangle), 'incompatible rank'
    assert len(image_shape) == 2 or len(image_shape)==3, 'specify two or three dimensional regions'
    n_dim = len(image_shape)
    shape = [np.ceil(image_shape[d]/rectangle[d]).astype(int) for d in range(n_dim)]
    # get the coordinates of the regular grid which divides the image into rectangular regions
    coords = [[n*rectangle[d] for n in range(shape[d])] for d in range(n_dim)]
    mesh = np.meshgrid(*coords)
    mesh_coords = np.stack([np.reshape(mesh[d], newshape=(-1,)) for d in range(n_dim)])
    bb = [tuple(mesh_coords[:,i]) + rectangle for i in range(mesh_coords.shape[1])]
    return bb

#%%
def image_to_plot(bounding_box):
    """
    Converts a bounding box in the image coordinate system to an annotation in plt.imshow()

    Parameters
    ----------
    bounding_box : tuple
        bounding box in 4-tuple format in image coordinate system. (origin top left on screen. X points down Y points right)
    """
    (x_img, y_img, w_img, h_img) = bounding_box # Image coord system
    return (y_img, x_img, h_img, w_img) # Plot coord system (x,y,w,h)


# %%    
def tileUnet(image_shape, input_shape, output_shape):
    """
    Tiles an image with the output shape of the Unet. 
    For each output region the corresponding input region is calculated.
    It is assumed that the output region is centered within the input region with the same number of bordering pixels on opposing sides.

  Parameters
    ----------
    image_shape : tuple
        dimension of the target image 
    input_shape : tuple
        dimension of the input region evaluated by the unet
    output_shape : tuple
        dimension of the output region / mask generated by the unet

    Returns
    -------
    dict
        holds two list of bounding boxes in 4-tuple format (x,y,w,h)
        offset (x,y) offset of output to input region 
    """
    # Step 1 Tile the image with the output region of the unet
    output_boxes = rectangularTiling(image_shape, output_shape)
    # Step 2 Regions are assumed to be centered. Use difference to calculate input regions
    assert (input_shape[0]-output_shape[0])%2==0, 'Cannot center input in x direction'
    assert (input_shape[1]-output_shape[1])%2==0, 'Cannot center input in y direction'
    delta_x = (input_shape[0]-output_shape[0])//2
    delta_y = (input_shape[1]-output_shape[1])//2

    input_boxes = []
    for bb_out in output_boxes:
        x,y,w,h = bb_out # unpack 4 tuple
        # compute and append input region
        #NOTE coordinates outside image region will occur
        input_boxes.append((x-delta_x,y-delta_y,w+2*delta_x,h+2*delta_y))
    
    return {'input_boxes': input_boxes, 'output_boxes': output_boxes, 'offset': (delta_x,delta_y)}

 # %%
def bb_lies_in_image_region(image_shape, boundingBox):
    """Checks if a bounding box lies completely within an image

    Parameters
    ----------
    image_shape : tuple
        dimensions of the image
    boundingBox : tuple
        4-tuple (x,y,w,h) bounding box in image cordinates

    Returns
    -------
    bool
        whether the boundingBox lies completely within the image region
    """
    # The image has it's top left corner at (0,0) there can be no negative coordinates
    (x,y,w,h) = boundingBox
    valid = (x>=0 and y>=0)
    # The bounding box may not protrude past the image borders
    valid = valid and x+w <= image_shape[0]
    valid = valid and y+h <= image_shape[1]
    return valid

# %% Extract imag patches given by a list of bounding boxes
def getImageTiles(image, boundingBoxes):
    """Cut out a collection of image tiles given by a list of bounding boxes

    Parameters
    ----------
    image : image tensor
        the image to cut tiles from
    boundingBoxes : list
        a list of 4-tuple (x,y,w,h) bounding boxes

    Returns
    -------
    list
        a list of image tensors showing the specified regions
    """
    tiles = [] # construct list of image tensors
    for bb in boundingBoxes:
        #print('cropping {}'.format(bb))
        # check if we can just crop out the bb from the image
        if bb_lies_in_image_region(image.shape, bb):
            tiles.append(tf.image.crop_to_bounding_box(image, bb[0], bb[1], bb[2], bb[3]))
        else:
            #TODO implement periodic borders
            print('{} violates image borders {}'.format(bb, image.shape))
    return tiles

def showTiles(tiles):
    """Plot a list of image tensors

    Parameters
    ----------
    tiles : list
        a list of tensors to plot
    """
    n = len(tiles)
    fig, ax = plt.subplots(n, sharex=True, figsize=(8,16))
    for i in range(n):
        ax[i].imshow(tiles[i])



# %%
def extendImageToBB(image, boundingBox):
    """Generates an image that is extended to fill a bounding box by mirroring at its sides

    Parameters
    ----------
    image : image tensor
        the image to be extended
    boundingBox : tuple
        4-tuple (x,y,w,h) bounding box in image coordinates.

    Returns
    -------
    image tensor
        the specified region where missing information was filled in by mirroring the image
    """
    # Compute the how much padding has to be generated
    (x,y,w,h) = boundingBox
    (w_img, h_img, c) = image.shape
    # x direction
    x_prepend = np.max([0, -x]) # If x<0 prepend |x| pixels
    x_append = np.max([0,x+w-w_img]) # If x+w > w_img append the difference
    # y direction
    y_prepend = np.max([0, -y])
    y_append = np.max([0,y+h-h_img])
    # Use tensorflow padding operation with 'REFLECT' option
    image_extended = tf.pad(image, paddings=[[x_prepend,x_append], # x dimension
                                             [y_prepend,y_append], # y dimension
                                             [0,0]], # channel dimension (unaltered)
                            mode='REFLECT') 
    return image_extended

# %%
def getRegionBoundary(bounding_boxes):
    """Compute the smallest bounding box that contains all bounding boxes in a list

    Parameters
    ----------
    bounding_boxes : list
        list of 4-tuple (x,y,w,h) bounding boxes

    Returns
    -------
    tuple
        4-tuple (x,y,w,h) bounding box 
    """
    n = len(bounding_boxes)
    assert n>=1, 'empty list'
    x_min, y_min, x_max, y_max = (0,0,0,0)
    for bb in bounding_boxes:
        (x,y,w,h) = bb
        x_min = np.min([x_min,x]) # topmost corner
        y_min = np.min([y_min,y]) # leftmost corner
        x_max = np.max([x_max,x+w]) # max bottom
        y_max = np.max([y_max,y+h]) # max right
    w_max = x_max - x_min # extension in x
    h_max = y_max - y_min # extension in y
    return (x_min,y_min,w_max,h_max) # (x,y,w,h)


# %% 

def getMirroredTiles(image, boundingBoxes):
    """Crop out a collection of bounding boxes from an image. If the bounding boxes extend past the image, mirror it at it's borders to fill in the missing values

    Parameters
    ----------
    image : image tensor
        the image to be cropped
    boundingBoxes : list
        a list of 4-tuple (x,y,w,h) bounding boxes that can extend past the image borders but not more than the image dimension

    Returns
    -------
    list
        a list of image tiles
    """
    # Step1 get the region covered by the bounding boxes
    region = getRegionBoundary(boundingBoxes)
    # Step2 extend the image to fit the required region
    image_extended = extendImageToBB(image, region)
    # Step3 shift all bounding boxes to account for the extension at the top left corner (new origo)
    shift_x = np.max([0,-region[0]]) # prepended pixels x
    shift_y = np.max([0,-region[1]]) # prepended pixels y
    bb_adjusted = [(x+shift_x, y+shift_y, w, h) for (x,y,w,h) in boundingBoxes]
    # Step3 cut out the tiles
    tiles = getImageTiles(image_extended,bb_adjusted)
    
    return tiles

#TODO convert list of image tensors to a batched numpy array
def listToBatch(imageList):
    image_shape  = imageList[0].shape
    n = len(imageList)
    batch = np.zeros((n,)+image_shape)
    for i, image in enumerate(imageList):
        batch[i] = image.numpy()
    return batch

def assembleTiles(tiles, boundingBoxes):
    """Assemble a list of tiles using the coordinates of a list of bounding boxes

    Parameters
    ----------
    tiles : list
        list of image tensors
    boundingBoxes : list
        list of nonoverlapping 4-tuple (x,y,w,h) bounding boxes in a common coordinate system used to place each tile

    Returns
    -------
    image tensor
        the assembled image
    """
    # Step 1 Determine the image region and allocate a suitable image tensor
    (x_min,y_min,w_max,h_max) = getRegionBoundary(boundingBoxes) # w,h give image size
    channels = tiles[0].shape[-1] # preserve the number of channels (assumed to be last dimenion in tensor)
    image = np.zeros((w_max,h_max,)+(channels,))
    # write tiles to the correct location in the image coordinate system (x,y) of region is origo / (0,0) in image
    for tile, bb in zip(tiles, boundingBoxes):
        (x,y,w,h) = bb # extract bounding box
        (x,y,w,h) = (x-x_min,y-y_min,w,h) # shift to image coordinates
        image[x:x+w,y:y+h,:] = tile # write tile to image
    return image

def centralCrop(image, image_size):
    """Crops out the central region as specified by image_size. The same number of pixels must be removed on each side

    Parameters
    ----------
    image : image tensor
        the image to crop
    image_size : tuple
        the dimensions of the output image

    Returns
    -------
    image tensor
        the croped image
    """
    given_size = image.shape
    assert (given_size[0]-image_size[0])%2==0, 'cannot center crop region in x direction'
    assert (given_size[1]-image_size[1])%2==0, 'cannot center crop region in x direction'
    dx = (given_size[0]-image_size[0])//2
    dy = (given_size[1]-image_size[1])//2
    image = tf.image.crop_to_bounding_box(image, dx, dy, given_size[0]-2*dx, given_size[1]-2*dy)
    return image

def cropToBB(image, boundingBox):
    return tf.image.crop_to_bounding_box(image, boundingBox[0], boundingBox[1], boundingBox[2], boundingBox[3])

#%% Tests
"""
test_image = tf.keras.preprocessing.image.load_img('../images/Abyssinian_4.jpg')
test_image = tf.keras.preprocessing.image.img_to_array(test_image)/255
aabb = rectangularTiling(test_image.shape,(100,200))
showTiling(test_image,aabb)

# %% Experiment to find out alignment of graphical and plot coordinate system
test_image = tf.keras.preprocessing.image.load_img('../images/Abyssinian_1.jpg')
test_image = tf.keras.preprocessing.image.img_to_array(test_image)/255
test_image[10:20,50:200,:] = np.zeros((10,150,3))
plt.imshow(test_image)
bb = (50,100,10,200)
bb_adj = image_to_plot(bb)
plt.gca().add_patch(plt.Rectangle(bb[0:2],bb[2],bb[3], color='blue'))
plt.gca().add_patch(plt.Rectangle(bb_adj[0:2],bb_adj[2],bb_adj[3], color='red'))
plt.xlabel('x Axis')
plt.ylabel('y Axis')
plt.text(10, 360, 'Black rect: (10,50,10,150) in image coords\nBlue rect: (50,100,10,200) in plot coords\nRed rect: (50,100,10,200) transposed to image coords')
plt.title('Coordinate systems in plt.imshow()')
plt.savefig('Coordinate Systems.png')

# %% Test Unet tiling

regions = tileUnet(test_image.shape, (110,110), (100,100))
showTiling(test_image,regions['output_boxes'])
showTiling(test_image,regions['input_boxes'])

# %% Test getImageTiles
inputTiles = getImageTiles(test_image, regions['input_boxes'])
outputTiles = getImageTiles(test_image, regions['output_boxes'])
showTiles(inputTiles)
showTiles(outputTiles)

# %% Test getRegionBoundary on a list of input boxes overlapping the test image
getRegionBoundary(regions['input_boxes'])

# %%
regions = tileUnet(test_image.shape, (300,400), (250,350))
showTiling(test_image, regions['output_boxes'])
showTiling(test_image, regions['input_boxes'])
inputTiles = getMirroredTiles(test_image,regions['input_boxes'])
showTiles(inputTiles)

# %%
showTiling(test_image, regions['output_boxes'])
image_reassembled = assembleTiles(inputTiles, regions['input_boxes'])
image_reassembled_cropped = cropToBB(image_reassembled, (regions['offset'][0],regions['offset'][1], test_image.shape[0], test_image.shape[1]))
showTiling(image_reassembled, regions['input_boxes'])
showTiling(image_reassembled_cropped, regions['output_boxes'])
"""
# %%


class UnetTiler3D():

    def __init__(self, image, mask=None, output_shape=(132,132,132), input_shape=(220,220,220)):
        """
        Uses a pretrained 3D unet to segment an arbitrary input volume.

        A rectangular tiling of the image volume with the unet output is spatially extended to get a collection of input regions. 
        The class reassembles the unet output to a segmentation mask with the same shape as the input image.

        Parameters
        ----------
        image : image tensor
            the input tensor
        output_shape : tuple
            shape of the segmentation output of the unet
        input_shape : tuple
            shape of the image input of the unet
        """
        self.image = image
        if mask is None:
            self.mask = np.zeros_like(image) # Allocate a tensor where the segmentation mask is stored
        else:
            assert image.shape == mask.shape, 'The mask and image array need to be of the same shape'
            self.mask = mask
        self.output_shape = output_shape
        self.input_shape = input_shape
        assert len(image.shape) == 3, 'Specify a single channel 3D image with format (x,y,z)'
        assert len(output_shape) == 3, 'Specify the extent of the output shape as (x,y,z)'
        assert len(input_shape) == 3, 'Specify the extent of the input shape as (x,y,z)'
        
        # Calculate the coordinate mesh of the tiling
        # Each list goes up to the last multiple of tile_shape smaller than image_shape => endpoint excluded
        self.x = list(range(0,image.shape[0],output_shape[0]))
        self.y = list(range(0,image.shape[1],output_shape[1]))
        self.z = list(range(0,image.shape[2],output_shape[2]))

        # Expose the shape of the tiling
        self.shape = (len(self.x),len(self.y),len(self.z))
    
    def __len__(self):
        return np.prod(self.shape)

    def _indexToCoordinates(self, i):
        """Convert a tile index to tiling coordinates

        Parameters
        ----------
        i : int
            tile index

        Returns
        -------
        x,y,z : int
            the coordinates of the tile in the tiling grid
        """     
         # Sanity check
        assert i >=0, 'index out of bounds'
        assert i < len(self), 'index out of bounds'
        # Convert index to the coordinates of the tile
        x = i // (self.shape[1]*self.shape[2]) # number of elements that you skip by moving one position in dim 0
        i = i % (self.shape[1]*self.shape[2])
        y = i // self.shape[2]
        z = i % self.shape[2]
        return x,y,z

    def _coordinatesToIndex(self,x,y,z):
        """Converts the coordinates of a tile in the tiling grid to it's index
        """
        assert (x,y,z) < self.shape and (x,y,z) >= (0,0,0), 'Coordinates out of bounds'
        i = x*self.shape[1]*self.shape[2]
        i += y*self.shape[2]
        i += z
        return i

    def _getOutputTile(self, i):
        """Returns an axis aligned boundary box defining the ith tile. 
        The input image is tiled with the output of the unet to get a segmentation mask of the same size.

        Parameters
        ----------
        i : int
            index of the output tile

        Returns
        -------
        tuple
            aabb coordinate tuple (x0,y0,z0,x1,y1,z1) (diagonal oposite corners that define a rectangular volume)
        """
        x,y,z = self._indexToCoordinates(i)
        # assemble the coordinates of the target chunk
        x0 = self.x[x]
        y0 = self.y[y]
        z0 = self.z[z]
        x1 = x0 + self.output_shape[0]
        y1 = y0 + self.output_shape[1]
        z1 = z0 + self.output_shape[2]
        return (x0,y0,z0,x1,y1,z1)

    def _getInputTile(self, i):
        aabb = self._getOutputTile(i) # get the aabb of the corresponding input tile 
        delta = np.subtract(self.input_shape,self.output_shape) // 2 # symmetric expansion in each direction
        # we have to subtract delta from the inital coords and add it to the stop coords
        delta = np.concatenate((-delta, delta))
        aabb = np.add(aabb,delta) # element wise addition
        return tuple(aabb)
        
    def _getSlice(self, index):
        # get the aabb of the unet input slice
        aabb = self._getInputTile(index)
        # clip the aabb if it protrudes from the image volume
        start = [ np.max([0, d]) for d in aabb[:3] ] # origo is at (0,0,0)
        stop = [ np.min([self.image.shape[i], aabb[i+3]]) for i in range(3) ]
        # calculate the padding in each direction
        pre_pad = [ np.max([0, -d]) for d in aabb[:3] ]
        post_pad = [ np.max([0, aabb[i+3] - self.image.shape[i] ]) for i in range(3) ]
        padding = tuple([ (pre_pad[i],post_pad[i]) for i in range(3) ] )
        #print('padding = {}'.format(padding))
        # extract the cliped slices from the h5 archive
        data = self.image[start[0]:stop[0],start[1]:stop[1],start[2]:stop[2]]
        # pad the slice to the required size
        data = np.pad(data, pad_width=padding, mode='reflect')
        return data
    
    def _writeSlice(self, index, slice):
        assert slice.shape == self.output_shape, 'Slice needs to have the output shape of the unet'
        assert index>=0 and index < len(self), 'Index out of bounds'
        aabb = self._getOutputTile(index) # retrieve aabb that belongs to the slice index
        #print('unet output mask target aabb : {}'.format(aabb))

        # clip the target aabb if it protrudes from the image volume
        start = [ np.max([0, d]) for d in aabb[:3] ] # origo is at (0,0,0)
        stop = [ np.min([self.image.shape[i], aabb[i+3]]) for i in range(3) ]
        #print('unet output mask target {} to {} :'.format(start,stop))

        # calculate the padding which was applied to the source 
        slice_start = [ np.max([0, -d]) for d in aabb[:3] ]
        slice_stop = [ np.max([0, aabb[i+3] - self.image.shape[i] ]) for i in range(3) ]
        #print('unet output mask crop from {} to {}'.format(slice_start,slice_stop))

        # crop the padding away
        slice_cropped = slice[slice_start[0]:-slice_stop[0] or None,
                              slice_start[1]:-slice_stop[1] or None,
                              slice_start[2]:-slice_stop[2] or None]
        
        # write the cropped slice to the target position in the mask
        self.mask[start[0]:stop[0],start[1]:stop[1],start[2]:stop[2]] = slice_cropped
        
    def process_sequential(self, unet):
        for i in tqdm(range(len(self)), desc='tiles processed'): # gives feedback on progress of for loop
            self._process_slice(unet, i)

    def process_mulithread(self, unet):
        executor = concurrent.futures.ThreadPoolExecutor()        
        futures = [executor.submit(self._process_slice(unet, i)) for i in range(len(self))]
        concurrent.futures.wait(futures)
        executor.shutdown()

    def _process_slice(self, unet, i):
        # Read input slice from volume
        input_slice = self._getSlice(i)
        #print('input shape : '.format(input_slice.shape))
        # Add batch and channel dimension and feed to unet
        output_slice = unet.predict(input_slice[np.newaxis,:,:,:,np.newaxis])
        output_mask = np.argmax(output_slice, axis=-1)[0,...] # use argmax on channels and remove batch dimension
        #print('unet output mask shape : '.format(input_slice.shape))
        self._writeSlice(i, output_mask)
            


# %%
